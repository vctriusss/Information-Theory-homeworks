{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 2. Машинное обучение\n",
    "## Камаев Виктор БИБ214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Байесовская классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Откроем файл names.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>percent</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1880</td>\n",
       "      <td>John</td>\n",
       "      <td>0.081541</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>William</td>\n",
       "      <td>0.080511</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1880</td>\n",
       "      <td>James</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1880</td>\n",
       "      <td>Charles</td>\n",
       "      <td>0.045167</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1880</td>\n",
       "      <td>George</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     name   percent  sex\n",
       "0  1880     John  0.081541  boy\n",
       "1  1880  William  0.080511  boy\n",
       "2  1880    James  0.050057  boy\n",
       "3  1880  Charles  0.045167  boy\n",
       "4  1880   George  0.043292  boy"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('baby-names.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем работать с данными, целевую переменную нужно закодировать. Так как это пол - бинарный признак, то можно воспользоваться обычным `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>percent</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1880</td>\n",
       "      <td>John</td>\n",
       "      <td>0.081541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1880</td>\n",
       "      <td>William</td>\n",
       "      <td>0.080511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1880</td>\n",
       "      <td>James</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1880</td>\n",
       "      <td>Charles</td>\n",
       "      <td>0.045167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1880</td>\n",
       "      <td>George</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year     name   percent  sex\n",
       "0  1880     John  0.081541    0\n",
       "1  1880  William  0.080511    0\n",
       "2  1880    James  0.050057    0\n",
       "3  1880  Charles  0.045167    0\n",
       "4  1880   George  0.043292    0"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sex_encoder = LabelEncoder()\n",
    "df['sex'] = sex_encoder.fit_transform(df['sex'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Разделим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df['name'], df['sex']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного (почти) переписал функции из семинара. Имхо так с ними работать и понимать их намного удобнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "from typing import Callable\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, feature_extraction_func: Callable, classification_func: Callable) -> None:\n",
    "        self.feature_extraction_func = feature_extraction_func\n",
    "        self.classification_func = classification_func\n",
    "\n",
    "\n",
    "    def fit(self, X_train: list[str], y_train: list[str]):\n",
    "\n",
    "        classes, freqs = defaultdict(int), defaultdict(int)\n",
    "\n",
    "        for sample, label in zip(X_train, y_train):\n",
    "            classes[label] += 1  # count classes frequencies\n",
    "\n",
    "            for feat in self.feature_extraction_func(sample):\n",
    "                freqs[label, feat] += 1          # count features frequencies\n",
    "\n",
    "        for label, feat in freqs:                # normalize features frequencies\n",
    "            freqs[label, feat] /= classes[label]\n",
    "\n",
    "        for c in classes:                       # normalize classes frequencies\n",
    "            classes[c] /= len(X_train)\n",
    "\n",
    "        self.classes = classes\n",
    "        self.freqs = freqs\n",
    "\n",
    "\n",
    "    def predict(self, X_test: list[str]):\n",
    "\n",
    "        res = np.zeros(len(X_test))\n",
    "\n",
    "        for i, sample in enumerate(X_test):\n",
    "            feats = self.feature_extraction_func(sample)\n",
    "\n",
    "            res[i] = self.classification_func(self.classes, self.freqs, feats)\n",
    "\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая реализация позволяет легко менять функции для получения признаков из имени, а также функции выбора класса\n",
    "\n",
    "В качестве первой функции выбора возьму функцию из семинара. Но обычный копипаст ломается на том, что может оказаться так, что набор (<последняя буква>, <класс>) есть либо только в тренировочной выборке, либо только в тестовой\n",
    "\n",
    "Чтобы бороться с этим буду смотреть на частоту, получаемую из словаря `freqs`. Если она нулевая (defauldict возвращает 0 по стандарту), то будем выдавать минимальный класс (по числу объектов тестовой выборки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_func_1(classes, freqs, features):\n",
    "    min_res, min_class = 1e9, None\n",
    "    \n",
    "    for label in classes:\n",
    "\n",
    "        res = -log(classes[label])\n",
    "\n",
    "        for feat in features:\n",
    "            if freqs[label, feat] == 0:  # handle lack of data\n",
    "                return min(classes, key=lambda l: classes[l])\n",
    "            \n",
    "            res += -log(freqs[label, feat])\n",
    "\n",
    "        if res < min_res:\n",
    "            min_class = label\n",
    "            min_res = res\n",
    "            \n",
    "    return min_class\n",
    "\n",
    "\n",
    "def extr_func_last_letter(sample: str) -> list[str]:\n",
    "    return (sample[-1])  # just last letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = NaiveBayesClassifier(extr_func_last_letter, clf_func_1)\n",
    "\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Предсказания\n",
    "\n",
    "Средняя доля правильных ответов - число совпадений / число объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7766795865633075"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf1.predict(X_test)\n",
    "\n",
    "score = sum(x == y for x, y in zip(y_test, pred)) / len(pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что средняя доля правильных ответов 0.78. Это довольно неплохо\n",
    "\n",
    "Обычно в задачах классификации берут метрики точности полноты (precision & recall), а также их композиции F1-score и ROC AUC\n",
    "\n",
    "Для простоты буду выводить `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         boy       0.75      0.84      0.79     38668\n",
      "        girl       0.81      0.72      0.76     38732\n",
      "\n",
      "    accuracy                           0.78     77400\n",
      "   macro avg       0.78      0.78      0.78     77400\n",
      "weighted avg       0.78      0.78      0.78     77400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred, \n",
    "                            target_names=sex_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Использование другой функции извлечения признаков из имени\n",
    "\n",
    "Попробуем использовать разные функции и посмотреть на метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_everything(feature_extraction_func: Callable, clf_func: Callable):\n",
    "    clf = NaiveBayesClassifier(feature_extraction_func, clf_func)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                                target_names=sex_encoder.inverse_transform([0, 1])))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки - первая и последняя буква"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         boy       0.76      0.81      0.79     38668\n",
      "        girl       0.80      0.75      0.77     38732\n",
      "\n",
      "    accuracy                           0.78     77400\n",
      "   macro avg       0.78      0.78      0.78     77400\n",
      "weighted avg       0.78      0.78      0.78     77400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_everything(lambda n: (n[0], n[-1]), clf_func_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики по этой модели сталее более однородными (значения для мальчиков и девочек стали ближе друг к другу). Но прироста в качестве модель не получила"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки - 2 последние буквы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         boy       0.73      0.63      0.68     38668\n",
      "        girl       0.67      0.77      0.72     38732\n",
      "\n",
      "    accuracy                           0.70     77400\n",
      "   macro avg       0.70      0.70      0.70     77400\n",
      "weighted avg       0.70      0.70      0.70     77400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_everything(lambda n: (n[-2], n[-1]), clf_func_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики стали сильно хуже. Скорее всего потому, что пары последних букв почти все уникальные. Из-за этого прогноз ближе к константе - распределении мальчик/девочка в тестовой выборке.\n",
    "\n",
    "Чтобы показать это можем вывести прогноз для имени целиком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         boy       0.74      0.56      0.64     38668\n",
      "        girl       0.65      0.80      0.72     38732\n",
      "\n",
      "    accuracy                           0.68     77400\n",
      "   macro avg       0.69      0.68      0.68     77400\n",
      "weighted avg       0.69      0.68      0.68     77400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_everything(lambda n: list(n), clf_func_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Используем другую функцию для классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_func_2(classes, freqs, features):\n",
    "    max_res, max_class = -1e9, None\n",
    "    \n",
    "    for label in classes:\n",
    "\n",
    "        res = classes[label]\n",
    "\n",
    "        for feat in features:\n",
    "            if freqs[label, feat] == 0:  # handle lack of data\n",
    "                return max(classes, key=lambda l: classes[l])\n",
    "            \n",
    "            res += freqs[label, feat]\n",
    "\n",
    "        if res > max_res:\n",
    "            max_class = label\n",
    "            max_res = res\n",
    "            \n",
    "    return max_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Смотрим на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         boy       0.75      0.84      0.79     38668\n",
      "        girl       0.82      0.72      0.77     38732\n",
      "\n",
      "    accuracy                           0.78     77400\n",
      "   macro avg       0.78      0.78      0.78     77400\n",
      "weighted avg       0.78      0.78      0.78     77400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "do_everything(extr_func_last_letter, clf_func_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что метрики почти не поменялись (**если сранивать со значениями где брали последнюю букву**). Это связано с тем, что в первом примере считается энтропия, а во втором - критерий Джини\n",
    "\n",
    "Но так вышло, что функции энтропии и $2*gini$ хорошо аппроксимируют друг друга на интервале вероятностей от 0 до 1. Поэтому отличия незначительны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Классификаторы из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем обучать классификаторы, текстовые данные надо превратить в числа, так как встроенные в sklearn классификаторы не умеют в буквы(\n",
    "\n",
    "Любая буква может быть закодирована в ASCII. Поэтому возьмем как признак - код последней буквы + отмасштабируем, начав отсчет с нуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = X_train.apply(lambda n: np.array(ord(n[-1]) - ord('a'))).to_numpy().reshape(-1, 1)\n",
    "X_test_vec = X_test.apply(lambda n: np.array(ord(n[-1]) - ord('a'))).to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим классификаторы из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73     38668\n",
      "           1       0.73      0.75      0.74     38732\n",
      "\n",
      "    accuracy                           0.74     77400\n",
      "   macro avg       0.74      0.74      0.74     77400\n",
      "weighted avg       0.74      0.74      0.74     77400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gauss = GaussianNB()\n",
    "gauss.fit(X_train_vec, y_train)\n",
    "\n",
    "pred = gauss.predict(X_test_vec)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67     38668\n",
      "           1       0.00      0.00      0.00     38732\n",
      "\n",
      "    accuracy                           0.50     77400\n",
      "   macro avg       0.25      0.50      0.33     77400\n",
      "weighted avg       0.25      0.50      0.33     77400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vctrius/Code/iad_homeworks/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vctrius/Code/iad_homeworks/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/vctrius/Code/iad_homeworks/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multi = MultinomialNB()\n",
    "multi.fit(X_train_vec, y_train)\n",
    "\n",
    "pred = multi.predict(X_test_vec)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут выдаются ошибки деления на ноль. Ради интереса посмотрим на предикты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А там все нули))\n",
    "\n",
    "Погуглив про мультиномиальное распределение пришел к выводу что можно попробовать брать больше чем один признак\n",
    "\n",
    "Тогда можно взять 2 последних буквы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = pd.concat([X_train.str.lower().str[-1].apply(ord), \n",
    "                         X_train.str.lower().str[-2].apply(ord)], \n",
    "                         axis=1) - ord('a')\n",
    "X_test_vec = pd.concat([X_test.str.lower().str[-1].apply(ord), \n",
    "                         X_test.str.lower().str[-2].apply(ord)], \n",
    "                         axis=1) - ord('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73     38668\n",
      "           1       0.73      0.73      0.73     38732\n",
      "\n",
      "    accuracy                           0.73     77400\n",
      "   macro avg       0.73      0.73      0.73     77400\n",
      "weighted avg       0.73      0.73      0.73     77400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi = MultinomialNB()\n",
    "multi.fit(X_train_vec, y_train)\n",
    "\n",
    "pred = multi.predict(X_test_vec)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики у этих классификаторов получились хуже, чем у наивного. Но зато появилась стабильность (метрика почти не зависит от класса)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2. Ирисы\n",
    "\n",
    "#### 0. Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris['data'], iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Разделим выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Обучим LDA (встроенный в sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis('eigen')\n",
    "lda.fit(X_train, y_train);\n",
    "\n",
    "pred = lda.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что встроенный классификатор дает ровно 0 ошибок, потому что он умный и делает все правильно. Теперь посмотрим на LDA из семинара\n",
    "\n",
    "#### 3. LDA из семинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_dimensionality(X, y, k):\n",
    "    '''\n",
    "    X - набор данных, y - метка, k - целевой размер\n",
    "    '''\n",
    "    label_ = list(set(y))\n",
    "\n",
    "    X_classify = {}\n",
    "\n",
    "    for label in label_:\n",
    "        X1 = np.array([X[i] for i in range(len(X)) if y[i] == label])\n",
    "        X_classify[label] = X1\n",
    "\n",
    "    mju = np.mean(X, axis=0)\n",
    "    mju_classify = {}\n",
    "\n",
    "    for label in label_:\n",
    "        mju1 = np.mean(X_classify[label], axis=0)\n",
    "        mju_classify[label] = mju1\n",
    "\n",
    "    #St = np.dot((X - mju).T, X - mju)\n",
    "\n",
    "    Sw = np.zeros((len(mju), len(mju)))  # Вычислить матрицу внутриклассовой дивергенции\n",
    "    for i in label_:\n",
    "        Sw += np.dot((X_classify[i] - mju_classify[i]).T,\n",
    "                     X_classify[i] - mju_classify[i])\n",
    "\n",
    "    # Sb=St-Sw\n",
    "\n",
    "    Sb = np.zeros((len(mju), len(mju)))  # Вычислить матрицу внутриклассовой дивергенции\n",
    "    for i in label_:\n",
    "        Sb += len(X_classify[i]) * np.dot((mju_classify[i] - mju).reshape(\n",
    "            (len(mju), 1)), (mju_classify[i] - mju).reshape((1, len(mju))))\n",
    "\n",
    "    eig_vals, eig_vecs = np.linalg.eig(\n",
    "        np.linalg.inv(Sw).dot(Sb))  # Вычислить собственное значение и собственную матрицу Sw-1 * Sb\n",
    "\n",
    "    sorted_indices = np.argsort(eig_vals)\n",
    "    topk_eig_vecs = eig_vecs[:, sorted_indices[:-k - 1:-1]]  # Извлекаем первые k векторов признаков\n",
    "    return topk_eig_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по документации sklearn, `LinearDiscriminantAnalysis` это сам LDA (который позволяет уменьшить размерность) + наивный байесовский классификатор\n",
    "\n",
    "Поэтому LDA возьемем из семинара, а классификатором восполбзуемся встроенным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = LDA_dimensionality(X_train, y_train, 1)\n",
    "X_train_lda = np.dot(X_train, w)\n",
    "X_test_lda = np.dot(X_test, w)\n",
    "\n",
    "lda = GaussianNB()\n",
    "lda.fit(X_train_lda, y_train);\n",
    "\n",
    "pred = lda.predict(X_test_lda)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И опять единичка) Причем при любом количестве выходных признаков (даже 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Изменение параметров классификатора\n",
    "\n",
    "Так как встроенный классификатор и так работает идеально, эффективней его делать некуда. Поэтому попробуем понизить ему метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for solv in ['eigen', 'lsqr', 'svd']:\n",
    "    lda = LinearDiscriminantAnalysis(solv)\n",
    "    lda.fit(X_train, y_train);\n",
    "\n",
    "    pred = lda.predict(X_test)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что датасет настолько базовый, что любой солвер выдает единицу\n",
    "\n",
    "Попробуем поиграться со специфичными для каждого солвера параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = [{'solver': 'svd', 'store_covariance': True},\n",
    "           {'solver': 'svd', 'tol': 0.1},\n",
    "           {'solver': 'lsqr', 'shrinkage': 'auto'}]\n",
    "\n",
    "for p in params:\n",
    "    lda = LinearDiscriminantAnalysis(**p)\n",
    "    lda.fit(X_train, y_train);\n",
    "\n",
    "    pred = lda.predict(X_test)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, ничего не помогает)\n",
    "\n",
    "При любом солвере (сингулярное разложение, через МНК, разложение на собственные значения) ничего не меняется. Также изменения специфичных параметров, таких как `store_covariance` (сохранение матрицы ковариаций), изменение порога `tol` на несколько порядков в обе стороны, а также автоматическое сокращение `shrinkage` метрику не меняют\n",
    "\n",
    "Слишком удачный датасет"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
